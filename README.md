# AI Order Taker

Demo of menu upload + ordering:

https://github.com/user-attachments/assets/b3643b8d-9fab-4ae9-9768-ca443a2dce16

Another demo of ordering with a seperate menu:

https://github.com/user-attachments/assets/2f1602ee-8ee4-421c-ac9d-9a9dd7112df9



A real-time AI-powered voice order taking system with streaming audio, intelligent menu processing, and live order management.

## ğŸ¯ Overview

This system allows customers to place orders through natural voice conversation with an AI that understands menu items, processes modifications, and maintains order state in real-time.

## ğŸ—ï¸ Architecture

- **Frontend**: React + TypeScript + Bootstrap (Vite dev server)
- **Backend**: FastAPI + WebSocket + WebRTC
- **Audio Pipeline**: Browser WebRTC â†’ STT (Whisper) â†’ Phi-3 LLM â†’ TTS (Orpheus) â†’ Browser
- **Order Management**: Real-time order tracking with WebSocket updates
- **Each pipeline stage (STT, LLM, TTS, Audio) runs in its own process, communicating via multiprocessing queues for robust, real-time streaming.**

## âœ¨ Features

### ğŸ¤ Voice Interface
- **Real-time audio streaming** via WebRTC from browser to backend
- **Speech-to-Text** using Whisper with GPU acceleration
- **Natural language processing** with Phi-3 Medium LLM
- **Text-to-Speech** using Orpheus model for AI responses
- **Ultra-low latency** audio pipeline optimized for real-time conversation

### ğŸ¯ Order Management
- **Live order display** with automatic WebSocket updates
- **Order modifications** (add, remove, change quantities)
- **Price calculation** with real-time totals
- **Order persistence** across conversation turns

### ğŸ½ï¸ Menu System
- **Menu upload** via web interface (image/text)
- **OCR processing** for menu image analysis
- **AI-powered menu parsing** with structured item extraction
- **Dynamic menu updates** without system restart

### ğŸ›ï¸ User Interface
- **Simple voice activation** - "Click to Start Order" button
- **Real-time transcription** display
- **Live order summary** with itemized list and totals
- **Menu image display** for customer reference

## ğŸš€ Quick Start

### Prerequisites
- Python 3.12+
- CUDA-compatible GPU (recommended)
- FFmpeg installed
- Node.js 18+ (for frontend)

### Installation

1. **Clone and setup environment:**
```bash
git clone <repository-url>
cd orderly

# Create virtual environment
python -m venv venv312
source venv312/bin/activate  # On Windows: venv312\Scripts\activate
```

2. **Install llama-cpp-python with CUDA support:**
```bash
# Build llama-cpp-python with CUDA support for GPU acceleration
CMAKE_ARGS="-DGGML_CUDA=on" pip install llama-cpp-python

# Install remaining Python dependencies
pip install -r backend/requirements.txt
```

3. **Download AI models:**
```bash
# Create models directory
mkdir -p models

# Download Phi-3 Medium LLM (required)
# Place Phi-3-medium-4k-instruct.gguf in models/ directory

# Download Orpheus TTS model (required)
# Place orpheus model files in models/ directory
```

4. **Setup frontend:**
```bash
cd frontend
npm install
```

5. **Configure API keys (optional):**
```bash
# For OpenAI menu analysis (optional)
echo "your-openai-api-key" > backend/open-ai-api-key.txt
```

### Running the System

1. **Start the backend:**
```bash
cd backend
python multiprocess_stt_llm_tts.py
```

2. **Start the frontend (in new terminal):**
```bash
cd frontend
npm run dev
```

3. **Access the application:**
- Frontend: http://localhost:5173
- Backend API: http://localhost:8002

## ğŸ“ Project Structure

```
orderly/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/                  # FastAPI routes and WebRTC integration
â”‚   â”œâ”€â”€ processes/            # Multiprocessing pipeline (STT, LLM, TTS, Audio)
â”‚   â”œâ”€â”€ processors/           # Model wrappers (Whisper, Orpheus, LLM, etc.)
â”‚   â”œâ”€â”€ utils/                # Utility modules (order tracking, etc.)
â”‚   â”œâ”€â”€ menus/                # Uploaded and processed menu images/text
â”‚   â”œâ”€â”€ prompts/              # Prompt templates for LLM
â”‚   â”œâ”€â”€ uploads/              # Temporary uploads (ignored)
â”‚   â”œâ”€â”€ STT_debug_audio/      # Debug audio files (ignored)
â”‚   â”œâ”€â”€ logs/                 # Backend logs (ignored)
â”‚   â”œâ”€â”€ multiprocess_stt_llm_tts.py  # Main backend entrypoint
â”‚   â”œâ”€â”€ OCRAndParseMenu.py    # OCR and menu parsing logic
â”‚   â”œâ”€â”€ decoder.py            # Audio decoding utilities
â”‚   â””â”€â”€ requirements.txt      # Backend Python dependencies
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ public/               # Static assets
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/       # React components (MenuUpload, OrderDisplay, etc.)
â”‚   â”‚   â”œâ”€â”€ hooks/            # Custom React hooks
â”‚   â”‚   â”œâ”€â”€ types/            # TypeScript types
â”‚   â”‚   â””â”€â”€ App.tsx           # Main React app
â”‚   â”œâ”€â”€ package.json          # Frontend dependencies
â”‚   â”œâ”€â”€ vite.config.ts        # Vite config
â”‚   â””â”€â”€ ...                   # Other config files
â”œâ”€â”€ models/                   # AI models (Phi-3, Orpheus, etc.)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ ... (other dev, venv, and external directories)
```
