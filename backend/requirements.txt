fastapi==0.104.1
uvicorn[standard]==0.24.0
websockets==12.0
python-multipart==0.0.6
pydantic==2.5.0
torch>=2.0.0
torchaudio>=2.0.0
numpy>=1.20.0

# LLM dependencies
# NOTE: For GPU acceleration, install with CUDA support:
# export CUDA_HOME=/usr/local/cuda
# export PATH=$CUDA_HOME/bin:$PATH 
# export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH
# CMAKE_ARGS="-DGGML_CUDA=on" pip install llama-cpp-python --force-reinstall --no-cache-dir
llama-cpp-python>=0.3.9

# Parakeet STT dependencies (optional)
# Option 1: NeMo toolkit (full featured)
nemo_toolkit[asr]>=1.20.0
omegaconf>=2.3.0
hydra-core>=1.3.0

# Option 2: ONNX-ASR (quantized, lightweight)
onnx_asr
onnxruntime-gpu  # GPU support for ONNX Runtime

# Orpheus TTS dependencies

# Extra dependencies for audio and WebRTC
soundfile
snac
aioRTc
pyaudio